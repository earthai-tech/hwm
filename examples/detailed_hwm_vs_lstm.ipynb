{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e3a2f7",
   "metadata": {},
   "source": [
    "\n",
    "# HWM: Adaptive Hammerstein-Wiener Modeling Toolkit\n",
    "\n",
    "[![License](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](LICENSE)  \n",
    "[![PyPI version](https://img.shields.io/pypi/v/hwm.svg)](https://pypi.org/project/hwm/)  \n",
    "[![Documentation Status](https://readthedocs.org/projects/hwm/badge/?version=latest)](https://hwm.readthedocs.io/en/latest/)\n",
    "\n",
    "HWM is a **Python toolkit for adaptive dynamic system modeling**, designed to capture complex nonlinear and linear relationships in data through the Hammerstein-Wiener architecture. With a flexible, modular design, HWM integrates seamlessly with [Scikit-learn](https://scikit-learn.org/), enabling streamlined workflows for regression, classification, and time-series forecasting tasks.\n",
    "\n",
    "---\n",
    "\n",
    "# Adaptive Hammerstein-Wiener and LSTM Modeling on KDD Cup Dataset\n",
    "\n",
    "This Jupyter Notebook demonstrates the use of the HWM toolkit for adaptive dynamic system modeling by applying both the Hammerstein-Wiener classifier and an LSTM neural network to the KDD Cup 1999 dataset. The goal is to classify network intrusions and evaluate the performance of intelligent models in handling complex, nonlinear relationships within the data.\n",
    "\n",
    "The workflow includes:\n",
    "\n",
    "1. **Data Loading and Resampling**: Loading the KDD Cup dataset and resampling to a manageable size for efficient processing.\n",
    "2. **Data Preprocessing**: Scaling numerical features and encoding categorical variables to prepare the data for modeling.\n",
    "3. **Model Training with Hammerstein-Wiener Classifier**: Utilizing the `HammersteinWienerClassifier` for classification tasks.\n",
    "4. **Hyperparameter Tuning**: Applying `RandomizedSearchCV` to optimize model parameters.\n",
    "5. **Evaluation and Visualization**: Assessing model performance using accuracy, prediction stability score (PSS), and time-weighted accuracy (TWA), along with plotting confusion matrices and ROC curves.\n",
    "6. **LSTM Model Training**: Implementing an LSTM neural network to handle sequence-based data and comparing its performance with the Hammerstein-Wiener classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d978d38",
   "metadata": {},
   "source": [
    "## üì¶ Importing Necessary Libraries\n",
    "\n",
    "First, we import all the necessary libraries and modules required for data handling, preprocessing, modeling, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956b43b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     RandomizedSearchCV, train_test_split\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, StandardScaler\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, LSTM\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, auc, confusion_matrix, roc_curve, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV, train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Import HWM toolkit modules\n",
    "from hwm.estimators import HammersteinWienerClassifier\n",
    "from hwm.metrics import prediction_stability_score, twa_score\n",
    "from hwm.utils import resample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12916894",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Setting the Data Path\n",
    "\n",
    "Define the path where the KDD Cup dataset is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data path\n",
    "data_path = r'F:\\repositories'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1afe6",
   "metadata": {},
   "source": [
    "## üìÅ Loading the KDD Cup 1999 Dataset\n",
    "\n",
    "We load the KDD Cup 1999 dataset, which is commonly used for network intrusion detection tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names as per KDD Cup 1999 dataset\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files',\n",
    "    'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
    "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "    'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
    "    'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "# Define continuous and categorical features\n",
    "continuous_features = [\n",
    "    'duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot',\n",
    "    'num_failed_logins', 'num_compromised', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'protocol_type', 'service', 'flag', 'land', 'logged_in',\n",
    "    'is_host_login', 'is_guest_login', 'root_shell', 'su_attempted',\n",
    "    'num_outbound_cmds'\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\n",
    "    os.path.join(data_path, 'kddcup.data_10_percent_corrected'),\n",
    "    names=column_names,\n",
    "    header=None\n",
    ")\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219b118",
   "metadata": {},
   "source": [
    "## üîÑ Resampling the Dataset\n",
    "\n",
    "To ensure efficient processing, we resample the dataset to 100,000 samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the dataset to 100,000 samples for efficiency\n",
    "data = resample_data(data, samples=100000, random_state=42)\n",
    "\n",
    "# Display the shape after resampling\n",
    "print(f\"Resampled data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1131a8f",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Data Preprocessing\n",
    "\n",
    "We preprocess the data by scaling numerical features and encoding categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable: 0 for 'normal.', 1 for any attack\n",
    "data['label'] = data['label'].apply(lambda x: 0 if x == 'normal.' else 1)\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Display the shape after preprocessing\n",
    "print(f\"Processed features shape: {X_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b71d83",
   "metadata": {},
   "source": [
    "## üîÄ Splitting the Data into Training and Testing Sets\n",
    "\n",
    "We split the preprocessed data into training and testing sets, ensuring that the split is stratified based on the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c84d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y.values, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Display the shapes of the splits\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d957f72",
   "metadata": {},
   "source": [
    "## üîß Defining a Custom ReLU Transformer\n",
    "\n",
    "We define a custom transformer that applies the ReLU activation function, which will be used in the Hammerstein-Wiener classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom transformer that applies the ReLU activation function.\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit method. Returns self.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply ReLU activation function.\"\"\"\n",
    "        return np.maximum(0, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2801835",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Initializing the Hammerstein-Wiener Classifier\n",
    "\n",
    "We initialize the `HammersteinWienerClassifier` with the custom ReLU transformers and specified parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500efa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Hammerstein-Wiener Classifier\n",
    "hw_model = HammersteinWienerClassifier(\n",
    "    nonlinear_input_estimator=ReLUTransformer(),\n",
    "    nonlinear_output_estimator=ReLUTransformer(),\n",
    "    p=9,\n",
    "    loss=\"cross_entropy\",\n",
    "    time_weighting=\"linear\",\n",
    "    batch_size=\"auto\",\n",
    "    optimizer='sgd',\n",
    "    learning_rate=0.001,\n",
    "    max_iter=173, \n",
    "    early_stopping=True,\n",
    "    verbose=1, \n",
    ")\n",
    "\n",
    "# Display the model parameters\n",
    "print(hw_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2e03a",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è Training the Hammerstein-Wiener Classifier\n",
    "\n",
    "We train the Hammerstein-Wiener classifier using the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Hammerstein-Wiener Classifier\n",
    "hw_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14939218",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Hyperparameter Tuning with RandomizedSearchCV\n",
    "\n",
    "We perform hyperparameter tuning using `RandomizedSearchCV` to find the best combination of parameters for the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096706b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'p': randint(1, 10),  # Dependency order from 1 to 10\n",
    "    'batch_size': randint(32, 128),  # Batch size between 32 and 128\n",
    "    'optimizer': ['sgd', 'adam', 'adagrad'],  # Optimizers to choose from\n",
    "    'learning_rate': uniform(0.0001, 0.01),  # Learning rate from 0.0001 to 0.01\n",
    "    'max_iter': randint(50, 200)  # Max iterations between 50 and 200\n",
    "}\n",
    "\n",
    "# Initialize the Hammerstein-Wiener Classifier with fixed components\n",
    "fixed_hw_model = HammersteinWienerClassifier(\n",
    "    nonlinear_input_estimator=ReLUTransformer(),\n",
    "    nonlinear_output_estimator=ReLUTransformer(),\n",
    "    loss=\"cross_entropy\",\n",
    "    time_weighting=\"linear\",\n",
    "    verbose=0, \n",
    "    batch_size=200, \n",
    "    early_stopping=True, \n",
    ")\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=fixed_hw_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of parameter settings sampled\n",
    "    scoring='accuracy',  # Evaluation metric\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to find the best parameters\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters and the corresponding score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bf646",
   "metadata": {},
   "source": [
    "## üìä Evaluating the Hammerstein-Wiener Classifier\n",
    "\n",
    "We use the best estimator from the hyperparameter tuning to make predictions and evaluate its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a842c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator to make predictions\n",
    "best_hw_model = random_search.best_estimator_\n",
    "y_pred_hw = best_hw_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Hammerstein-Wiener Classifier\n",
    "accuracy_hw = accuracy_score(y_test, y_pred_hw)\n",
    "y_pred_proba_hw = best_hw_model.predict_proba(X_test)[:, 1]\n",
    "pss_hw = prediction_stability_score(y_pred_proba_hw)\n",
    "twa_hw = twa_score(y_test, y_pred_hw, alpha=0.9)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Hammerstein-Wiener Classifier Accuracy: {accuracy_hw:.4f}\")\n",
    "print(f\"Hammerstein-Wiener Classifier PSS: {pss_hw:.4f}\")\n",
    "print(f\"Hammerstein-Wiener Classifier TWA: {twa_hw:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0492dfe",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Plotting Results\n",
    "\n",
    "We define a function to plot the Confusion Matrix and ROC Curve for the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_true, y_pred, y_pred_proba, title):\n",
    "    \"\"\"\n",
    "    Plots the Confusion Matrix and ROC Curve for the given predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True target values.\n",
    "    y_pred : array-like\n",
    "        Predicted target values.\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities for the positive class.\n",
    "    title : str\n",
    "        Title for the plots.\n",
    "    \"\"\"\n",
    "    # Confusion Matrix\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
    "    plt.title(f'Confusion Matrix - {title}')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc_score = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'{title} (AUC = {roc_auc_score:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15726c5",
   "metadata": {},
   "source": [
    "\n",
    "## üìà Plotting Hammerstein-Wiener Classifier Results\n",
    "\n",
    "We visualize the performance of the Hammerstein-Wiener classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for Hammerstein-Wiener Classifier\n",
    "plot_results(y_test, y_pred_hw, y_pred_proba_hw, 'Hammerstein-Wiener Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5874042f",
   "metadata": {},
   "source": [
    "## üß† Defining and Training the LSTM Model\n",
    "\n",
    "We implement an LSTM neural network to handle sequence-based data and compare its performance with the Hammerstein-Wiener classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acf299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of features\n",
    "n_features = X_processed.shape[1]\n",
    "\n",
    "# Define the number of timesteps\n",
    "timesteps = 9  # Should match the 'p' parameter used in Hammerstein-Wiener model\n",
    "\n",
    "def create_sequences(X, y, timesteps):\n",
    "    \"\"\"\n",
    "    Creates input sequences and corresponding targets for LSTM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        Feature matrix.\n",
    "    y : ndarray\n",
    "        Target vector.\n",
    "    timesteps : int\n",
    "        Number of timesteps for each input sequence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_seq : ndarray\n",
    "        Array of input sequences.\n",
    "    y_seq : ndarray\n",
    "        Array of target values corresponding to each sequence.\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        X_seq.append(X[i:i + timesteps])\n",
    "        y_seq.append(y[i + timesteps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create sequences for LSTM\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, timesteps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, timesteps)\n",
    "\n",
    "# Verify the shapes\n",
    "print(f'X_train_seq shape: {X_train_seq.shape}')\n",
    "print(f'y_train_seq shape: {y_train_seq.shape}')\n",
    "print(f'X_test_seq shape: {X_test_seq.shape}')\n",
    "print(f'y_test_seq shape: {y_test_seq.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ec190",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Building the LSTM Model\n",
    "\n",
    "We build and compile the LSTM model using TensorFlow's Keras API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f94585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, input_shape=(timesteps, n_features)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6871300",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Training the LSTM Model\n",
    "\n",
    "We train the LSTM model using the training sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a447a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LSTM model\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc519c",
   "metadata": {},
   "source": [
    "\n",
    "## üìä Evaluating the LSTM Model\n",
    "\n",
    "We evaluate the trained LSTM model on the test sequences and compute relevant metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the LSTM Model\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
    "y_pred_proba_lstm = lstm_model.predict(X_test_seq).flatten()\n",
    "y_pred_lstm = (y_pred_proba_lstm >= 0.5).astype(int)\n",
    "pss_lstm = prediction_stability_score(y_pred_proba_lstm)\n",
    "twa_lstm = twa_score(y_test_seq, y_pred_lstm, alpha=0.9)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"LSTM Accuracy: {lstm_accuracy:.4f}\")\n",
    "print(f\"LSTM PSS: {pss_lstm:.4f}\")\n",
    "print(f\"LSTM TWA: {twa_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c6973",
   "metadata": {},
   "source": [
    "## üìà Plotting LSTM Model Results\n",
    "\n",
    "We visualize the performance of the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for LSTM Model\n",
    "plot_results(y_test_seq, y_pred_lstm, y_pred_proba_lstm, 'LSTM Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc2b5c",
   "metadata": {},
   "source": [
    "## üÜö Comparing ROC Curves Between Models\n",
    "\n",
    "We compare the ROC curves of both the Hammerstein-Wiener classifier and the LSTM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve for Hammerstein-Wiener Classifier\n",
    "fpr_hw, tpr_hw, _ = roc_curve(y_test, y_pred_proba_hw)\n",
    "roc_auc_hw = auc(fpr_hw, tpr_hw)\n",
    "\n",
    "# Compute ROC curve for LSTM Model\n",
    "fpr_lstm, tpr_lstm, _ = roc_curve(y_test_seq, y_pred_proba_lstm)\n",
    "roc_auc_lstm = auc(fpr_lstm, tpr_lstm)\n",
    "\n",
    "# Plot both ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr_hw, tpr_hw, label=f'Hammerstein-Wiener (AUC = {roc_auc_hw:.4f})')\n",
    "plt.plot(fpr_lstm, tpr_lstm, label=f'LSTM (AUC = {roc_auc_lstm:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dad440",
   "metadata": {},
   "source": [
    "## üìù Summary of Results\n",
    "\n",
    "We summarize the performance metrics of both models for easy comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Summary of Results\n",
    "print(\"Summary of Results:\")\n",
    "print(f\"Hammerstein-Wiener Classifier Accuracy: {accuracy_hw:.4f}\")\n",
    "print(f\"Hammerstein-Wiener Classifier PSS: {pss_hw:.4f}\")\n",
    "print(f\"Hammerstein-Wiener Classifier TWA: {twa_hw:.4f}\")\n",
    "print(f\"LSTM Accuracy: {lstm_accuracy:.4f}\")\n",
    "print(f\"LSTM PSS: {pss_lstm:.4f}\")\n",
    "print(f\"LSTM TWA: {twa_lstm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
